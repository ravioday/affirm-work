1.How long did you spend working on the problem? What did you find to be the most difficult part?

Answers: 4 hours

2.How would you modify your data model or code to account for an eventual introduction of new,
as-of-yet unknown types of covenants, beyond just maximum default likelihood and state restrictions?

Answer: I will create, a new restrictions table in the database, rather than adding another column for the new restriction
on the covenant table and every covenant will have one or many restrictions.

covenant ->> has_many restrictions

Restriction records can have a type if need to suggest what type of restriction it is.


3. How would you architect your solution as a production service wherein new facilities
can be introduced at arbitrary points in time. Assume these facilities become available
by the finance team emailing your team and describing the addition with a new set of CSVs

Answer: I will create a job script / rake task to ingest this csv into the database.


4.Your solution most likely simulates the streaming process by directly calling a method
in your code to process the loans inside of a for loop.
What would a REST API look like for this same service? Stakeholders using the API will need,
at a minimum, to be able to request a loan be assigned to a facility, and read the funding status of a loan,
as well as query the capacities remaining in facilities.

Answer: maybe something like the following:

// Assuming a loan match needs to be persisted in our system for review by the user,
//To create a new loan match, resource.
 POST /loan/match body {loan: id, ...} => { match_id, loan_id, matched_facility: { ... } }

// read the funding status of a loan

GET /loan/{id} => {...loanDetails}

// query the capacities remaining in facilities
GET /facilities => [{facility_id: 1, capacity: 10}, {facility_id: 2, capacity: 7}]


5.How might you improve your assignment algorithm if you were permitted to assign loans in batch rather than streaming?
We are not looking for code here, but pseudo code or description of a revised algorithm appreciated.

Answer: Rather than sequentially reading input from the stream, I will use a concurrent operations queue, to facilitate,
operations in parallel

const tasks  = [allLoanMatchTasks]
JobsQueue jq = new JobsQueue(allLoanMatchTasks, numberOfParallelOps)

// run will start dequeing items from the queue and will run the specified number of tasks in parallel
jq.run()

Caution: The data structures that well will use for persistence results of the tasks, will need to provide some guarantee of atomicity,
else we will have to address inconsistency by locking and synchronizing accesses to the data-structure.

Typically: In such a situation, we will need a lock that blocks reads when a write is in progress to prevent stale read or readers-writers problem

6.Discuss your solutionâ€™s runtime complexity
Answer:
    For every loan match
    Time complexity is: O(n) + O(n*log(n)) =~ O((1+n)*log(n) =~ O(n*log(n))
    Thus for n-loan match requests
    Time complexity: O(n*n*log(n))
